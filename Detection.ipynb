{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymKNtC-rbybv"
   },
   "source": [
    "# ***1: Import Libraries***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:08:44.870288Z",
     "start_time": "2025-03-30T14:08:39.538573Z"
    },
    "id": "cmPhFkCHZha-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import Dense, LSTM, Embedding, SpatialDropout1D\n",
    "from keras.src.legacy.preprocessing.text import Tokenizer\n",
    "from keras.api.preprocessing.sequence import pad_sequences\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "from keras.api.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:08.556603Z",
     "start_time": "2025-03-30T14:09:59.146222Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y-4dbYkKzKmw",
    "outputId": "970e6d09-ce53-460c-eaa7-32b217050f5f"
   },
   "outputs": [],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNgKV7HjcB1s"
   },
   "source": [
    "# ***Read Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:18.445168Z",
     "start_time": "2025-03-30T14:10:18.361535Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rbws4wWPzKlW",
    "outputId": "08169b39-b5a3-4b62-e753-3fd191209a72"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2iGtMX0cIwV"
   },
   "source": [
    "# ***Preprocessing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:21.809837Z",
     "start_time": "2025-03-30T14:10:21.778076Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WW1s65AYEAUb",
    "outputId": "f28a9153-4d0b-480d-ef28-3ffa1a2364d9"
   },
   "outputs": [],
   "source": [
    "# Derive a binary label based on annotations:\n",
    "df['label'] = np.where((df['hate_speech_count'] + df['offensive_language_count']) > df['neither_count'], 1, 0)\n",
    "print(\"Dataset shape after adding label:\", df.shape)\n",
    "print(df[['hate_speech_count', 'offensive_language_count', 'neither_count', 'label']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCMSQrEicVCh"
   },
   "source": [
    "# **Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:25.152508Z",
     "start_time": "2025-03-30T14:10:24.844626Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "Y3NppaN7znQ6",
    "outputId": "af536e1f-9b05-4e95-822b-115821e5292d"
   },
   "outputs": [],
   "source": [
    "# 1.Distribution of final labels\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='label', data=df)\n",
    "plt.title(\"Distribution of Tweets by Final Label (0: Neither, 1: Hate/Offensive)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:28.304773Z",
     "start_time": "2025-03-30T14:10:28.298052Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtdpz05AEEwy",
    "outputId": "ceeb1bde-433f-4841-c743-cae076ae79ac"
   },
   "outputs": [],
   "source": [
    "# 2.Check tweet counts and basic statistics\n",
    "if 'tweet' in df.columns:\n",
    "    print(\"Sample tweets:\")\n",
    "    print(df['tweet'].head())\n",
    "else:\n",
    "    print(\"Column 'tweet' not found. Please adjust the code to use the correct text column.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNrl7dXycZcN"
   },
   "source": [
    "# ***Continue Preprocessing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:30.514703Z",
     "start_time": "2025-03-30T14:10:30.505741Z"
    },
    "id": "nLvFZyLqzpvt"
   },
   "outputs": [],
   "source": [
    "# Function to clean text: lowercasing, removing URLs, mentions, hashtags, special characters/punctuation\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text) # remove URLs\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text) # remove usernames/handles\n",
    "    text = re.sub(r'#[A-Za-z0-9_]+', '', text) # remove hashtags\n",
    "    text = re.sub(r'[^a-z\\s]', '', text) # remove punctuation, numbers, special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # remove extra whitespace\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:32.597919Z",
     "start_time": "2025-03-30T14:10:32.579325Z"
    },
    "id": "QhPhLfIDzrpG"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:34.613919Z",
     "start_time": "2025-03-30T14:10:34.608118Z"
    },
    "id": "DR1JMRXIztjp"
   },
   "outputs": [],
   "source": [
    "# Preprocessing function:\n",
    "def preprocess_text(text):\n",
    "    text = clean_text(text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:39.748116Z",
     "start_time": "2025-03-30T14:10:36.274013Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "xyhnXH2DGFNL",
    "outputId": "20450af3-f055-4b0b-c920-86668bf14918"
   },
   "outputs": [],
   "source": [
    "# Apply Preprocessing and Visualize Text Lengths\n",
    "if 'tweet' in df.columns:\n",
    "    df['clean_text'] = df['tweet'].apply(preprocess_text)\n",
    "    # Visualize distribution of clean text lengths\n",
    "    df['text_length'] = df['clean_text'].apply(lambda x: len(x.split()))\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.histplot(df['text_length'], bins=30, kde=True)\n",
    "    plt.title(\"Distribution of Clean Text Lengths\")\n",
    "    plt.xlabel(\"Number of words\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Tweet text column not found. Please ensure the dataset has a column for tweet text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sz5lIsdecwtc"
   },
   "source": [
    "# ***Split The Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:43.738168Z",
     "start_time": "2025-03-30T14:10:43.331151Z"
    },
    "id": "0UgbJDqYzy3y"
   },
   "outputs": [],
   "source": [
    "# Data Splitting and Feature Extraction for Traditional ML Models\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['clean_text']).toarray()\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tfidf_vectorizer using pickle\n",
    "import pickle\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tfidf_vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Tfidf Vectorizer saved as tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:45.779293Z",
     "start_time": "2025-03-30T14:10:45.131155Z"
    },
    "id": "9UoeEmGlz0np"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into train, validation, and test sets (70% train, 15% val, 15% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tfidf, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:10:46.758691Z",
     "start_time": "2025-03-30T14:10:46.753081Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXx68YXBz2Vx",
    "outputId": "25a85edb-3140-4c1e-eca2-ee9d4fdafd11"
   },
   "outputs": [],
   "source": [
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRRMPD66c5qS"
   },
   "source": [
    "# ***ML Models Training***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:13:14.032975Z",
     "start_time": "2025-03-30T14:10:49.394252Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVLefAaIz4Wf",
    "outputId": "d2df92d2-6e48-435c-953b-701f7896fab6"
   },
   "outputs": [],
   "source": [
    "#Train Traditional Machine Learning Models\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=200),\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    'KNeighbors': KNeighborsClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted', zero_division=0)\n",
    "    results[model_name] = {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1}\n",
    "    print(f\"{model_name} -- Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nValidation Set Performance Comparison:\")\n",
    "print(pd.DataFrame(results).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_yN--E4UdCSK"
   },
   "source": [
    "# ***Prepare the Dataset for NN (DL)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:13:21.659428Z",
     "start_time": "2025-03-30T14:13:21.112703Z"
    },
    "id": "dacWTn9sz7yr"
   },
   "outputs": [],
   "source": [
    "#Prepare Data for LSTM-based Deep Learning Model\n",
    "max_features = 5000  # vocabulary size\n",
    "maxlen = 100         # maximum sequence length\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features, lower=True)\n",
    "tokenizer.fit_on_texts(df['clean_text'])\n",
    "X_seq = tokenizer.texts_to_sequences(df['clean_text'])\n",
    "X_seq = pad_sequences(X_seq, maxlen=maxlen)\n",
    "\n",
    "X_train_seq, X_temp_seq, y_train_seq, y_temp_seq = train_test_split(X_seq, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val_seq, X_test_seq, y_val_seq, y_test_seq = train_test_split(X_temp_seq, y_temp_seq, test_size=0.5, random_state=42, stratify=y_temp_seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0ZVPCr7dUL9"
   },
   "source": [
    "# ***DL Model Training***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:15:06.755683Z",
     "start_time": "2025-03-30T14:13:27.566132Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "WCtT2TPjz-Hd",
    "outputId": "a931bc78-8e27-43c5-f4c3-45e61e0091a2"
   },
   "outputs": [],
   "source": [
    "#Build and Train the LSTM Model\n",
    "embedding_dim = 128\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(max_features, embedding_dim, input_length=maxlen))\n",
    "lstm_model.add(SpatialDropout1D(0.2))\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))  # Binary classification (0: Neither, 1: Hate/Offensive)\n",
    "\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "lstm_model.summary()\n",
    "\n",
    "# Early stopping callback to prevent overfitting\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "history = lstm_model.fit(X_train_seq, y_train_seq,\n",
    "                         epochs=10, batch_size=64,\n",
    "                         validation_data=(X_val_seq, y_val_seq),\n",
    "                         callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcwMG4aGdgvj"
   },
   "source": [
    "# ***Saving DL LSTM Model and Tokenizer***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:15:17.053905Z",
     "start_time": "2025-03-30T14:15:16.948546Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCfShyNUdeMY",
    "outputId": "2b0e4eeb-6632-41e5-da4e-ef83fed4b142"
   },
   "outputs": [],
   "source": [
    "# Save the LSTM model\n",
    "lstm_model.save('lstm_model.h5')\n",
    "print(\"LSTM model saved as lstm_model.h5\")\n",
    "\n",
    "# Save the tokenizer using pickle\n",
    "import pickle\n",
    "with open('tokenizer.pkl', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Tokenizer saved as tokenizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NP8GqXdkdnue"
   },
   "source": [
    "# ***DL LSTM Evaluation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:15:55.329707Z",
     "start_time": "2025-03-30T14:15:53.728996Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ur6wOaud0F_6",
    "outputId": "2751829e-7ac1-41c3-fc62-2282aa405ac8"
   },
   "outputs": [],
   "source": [
    "# Evaluate the LSTM Model\n",
    "loss, accuracy = lstm_model.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
    "print(\"LSTM Test Loss:\", loss)\n",
    "print(\"LSTM Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:16:02.810495Z",
     "start_time": "2025-03-30T14:16:00.484575Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYzE3MIE0HgL",
    "outputId": "7aa71d03-4220-484d-8ba8-f443c0981911"
   },
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "y_pred_seq = (lstm_model.predict(X_test_seq) > 0.5).astype(\"int32\")\n",
    "print(\"LSTM Classification Report:\")\n",
    "print(classification_report(y_test_seq, y_pred_seq, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4pBZR8DduVR"
   },
   "source": [
    "# ***ML Modesl Evaluation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:16:13.672027Z",
     "start_time": "2025-03-30T14:16:07.055346Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KqPi_fvZ0Jx6",
    "outputId": "a69fe4a7-28e7-41ca-bf14-a2514addfbfc"
   },
   "outputs": [],
   "source": [
    "#Evaluate Traditional Models on Test Set and Compare\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name} on Test Set...\")\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_test_pred, zero_division=0))\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmsE-hyud2mB"
   },
   "source": [
    "# ***Saving the best model in ML models after evaluation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:16:30.693812Z",
     "start_time": "2025-03-30T14:16:29.778840Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JfZkru6W0LwX",
    "outputId": "364f9532-1ef5-4af1-bd23-a06f63aff666"
   },
   "outputs": [],
   "source": [
    "#Save the Best Performing Model for Deployment\n",
    "best_model = models['XGBoost']\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(\"Best model saved as best_model.pkl.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_8lj960d9PW"
   },
   "source": [
    "# ***Deployment for both ML and DL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:21:54.300171Z",
     "start_time": "2025-03-30T14:21:54.288847Z"
    },
    "id": "6TksHAqg0N0p"
   },
   "outputs": [],
   "source": [
    "# Simple Deployment Example\n",
    "def predict_tweet(text, model, tfidf_vectorizer, tokenizer=None, use_lstm=False):\n",
    "    text_clean = preprocess_text(text)\n",
    "    if use_lstm:\n",
    "        seq = tokenizer.texts_to_sequences([text_clean])\n",
    "        seq = pad_sequences(seq, maxlen=maxlen)\n",
    "        pred = lstm_model.predict(seq)[0][0]\n",
    "        return 1 if pred > 0.5 else 0\n",
    "    else:\n",
    "        vec = tfidf_vectorizer.transform([text_clean]).toarray()\n",
    "        return model.predict(vec)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAifb7ffel8d"
   },
   "source": [
    "# ***Load the models ML and DL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:22:00.089725Z",
     "start_time": "2025-03-30T14:21:59.158980Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "as5VTul7eoy3",
    "outputId": "00109717-52a4-4af2-e106-7c6f27c69176"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('best_model.pkl', 'rb') as f:\n",
    "    best_ml_model = pickle.load(f)\n",
    "\n",
    "print(\"Model loaded successfully into best_ml_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:22:08.497504Z",
     "start_time": "2025-03-30T14:22:08.390664Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "itdL2w2EePMl",
    "outputId": "1f0c1f08-b485-488e-f897-c911a402bdb2"
   },
   "outputs": [],
   "source": [
    "from keras.api.models import load_model\n",
    "import pickle\n",
    "\n",
    "# Load LSTM model\n",
    "lstm_model = load_model('lstm_model.h5')\n",
    "\n",
    "# Load tokenizer\n",
    "with open('tokenizer.pkl', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYWLGiQ2exmm"
   },
   "source": [
    "# ***Test ML***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:22:12.146759Z",
     "start_time": "2025-03-30T14:22:11.790971Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwEdk2qf0Pr9",
    "outputId": "7fab541b-7dd9-4a43-ae3c-7cd096669f4d"
   },
   "outputs": [],
   "source": [
    "# Tradtional ML\n",
    "sample_tweet = \"What a beautiful day, everything Sucks!\"\n",
    "prediction = predict_tweet(sample_tweet, best_model, tfidf_vectorizer)\n",
    "print(\"Prediction for sample tweet (0: neither, 1: hate/offensive):\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP6ZYvSRe1Lp"
   },
   "source": [
    "# ***Test LSTM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T14:22:16.263220Z",
     "start_time": "2025-03-30T14:22:15.385941Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hUfbIDydOKJ",
    "outputId": "e8bac8b4-d1a3-4b6c-b5c6-29f146262813"
   },
   "outputs": [],
   "source": [
    "# LSTM\n",
    "sample_tweet = \"What a beautiful day, everything sucks!\"\n",
    "prediction_lstm = predict_tweet(sample_tweet, lstm_model, tfidf_vectorizer, tokenizer=tokenizer, use_lstm=True)\n",
    "print(\"Prediction for sample tweet (0: neither, 1: hate/offensive):\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrwOs4fdeXa8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
